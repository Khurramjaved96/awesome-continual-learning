# Awesome-continual-learning

## Classic Literature 
[Catastrophic Forgetting in Connectionist Networks (French, 1999)](https://www.researchgate.net/publication/228051810_Catastrophic_Forgetting_in_Connectionist_Networks)

[Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory](https://www.ncbi.nlm.nih.gov/pubmed/7624455)

## Rehearsal Based Incremental Learning 
[iCaRL: Incremental Classifier and Representation Learning, CVPR2017](https://arxiv.org/abs/1611.07725)

[MER : Learning to Learn without Forgetting by Maximizing Transfer and Minimizing Interference](https://arxiv.org/abs/1810.11910)

## Knowledge Distillation
[Distilling the Knowledge in a Neural Network, 2015](https://arxiv.org/abs/1503.02531)

[Learning without Forgetting, 2016](https://arxiv.org/abs/1606.09282)

## Knowledge Retention Methods
[(EWC)Overcoming catastrophic forgetting in neural networks, PNAS](https://arxiv.org/pdf/1612.00796.pdf)

[(MAS) Memory Aware Synapses: Learning what (not) to forget, ECCV18](https://eccv2018.org/openaccess/content_ECCV_2018/papers/Rahaf_Aljundi_Memory_Aware_Synapses_ECCV_2018_paper.pdf)

[(SI) Continual Learning Through Synaptic Intelligence](https://arxiv.org/pdf/1703.04200.pdf)

[(GEM) Gradient Episodic Memory for Continual Learning, NIPS17](https://arxiv.org/pdf/1706.08840.pdf)

## Dual Memory Networks
[FearNet: Brain-Inspired Model for Incremental Learning, ICLR18](https://openreview.net/forum?id=SJ1Xmf-Rb)

## Selective Networks 
[(XdG) Alleviating catastrophic forgetting using contextdependent gating and synaptic stabilization, PNAS](https://www.pnas.org/content/pnas/115/44/E10467.full.pdf)

[PathNet: Evolution Channels Gradient Descent in Super Neural Networks](https://arxiv.org/abs/1701.08734)
